package com.jaryd.voiphone.video

import android.annotation.SuppressLint
import android.app.Activity
import android.content.ContentValues
import android.content.Context
import android.graphics.*
import android.hardware.camera2.*
import android.hardware.camera2.params.MeteringRectangle
import android.media.ImageReader
import android.os.Environment
import android.os.Handler
import android.os.HandlerThread
import android.util.Log
import android.util.Range
import android.util.Size
import android.util.SparseIntArray
import android.view.Surface
import android.view.TextureView
import java.io.File
import java.io.FileOutputStream
import java.util.*
import java.util.concurrent.Semaphore
import java.util.concurrent.TimeUnit

open class CameraImp(val context: Context){

    companion object {

        /**
         * Conversion from screen rotation to JPEG orientation.
         */
        private val ORIENTATIONS = SparseIntArray()

        init {
            ORIENTATIONS.append(Surface.ROTATION_0, 90)
            ORIENTATIONS.append(Surface.ROTATION_90, 0)
            ORIENTATIONS.append(Surface.ROTATION_180, 270)
            ORIENTATIONS.append(Surface.ROTATION_270, 180)
        }

        /**
         * Tag for the [Log].
         */
        private val TAG = "Camera2BasicFragment"

        /**
         * Camera state: Showing camera preview.
         */
        private val STATE_PREVIEW = 0

        /**
         * Camera state: Waiting for the focus to be locked.
         */
        private val STATE_WAITING_LOCK = 1

        /**
         * Camera state: Waiting for the exposure to be precapture state.
         */
        private val STATE_WAITING_PRECAPTURE = 2

        /**
         * Camera state: Waiting for the exposure state to be something other than precapture.
         */
        private val STATE_WAITING_NON_PRECAPTURE = 3

        /**
         * Camera state: Picture was taken.
         */
        private val STATE_PICTURE_TAKEN = 4

        /**
         * Max preview width that is guaranteed by Camera2 API
         */
        private val MAX_PREVIEW_WIDTH = 1920

        /**
         * Max preview height that is guaranteed by Camera2 API
         */
        private val MAX_PREVIEW_HEIGHT = 1080
    }

    /**
     * ID of the current [CameraDevice].
     */
    private lateinit var cameraId: String

    /**
     */

    /**
     * A [CameraCaptureSession] for camera preview.
     *
     */
    private var captureSession: CameraCaptureSession? = null

    /**
     * A reference to the opened [CameraDevice].
     */
    private var mCameraDevice: CameraDevice? = null

    /**
     * The [android.util.Size] of camera preview.
     */
    private lateinit var previewSize: Size

    private lateinit var previewRequestBuilder: CaptureRequest.Builder

    /**
     * [CaptureRequest] generated by [.previewRequestBuilder]
     */
    private lateinit var previewRequest: CaptureRequest


    /**
     * A [Semaphore] to prevent the app from exiting before closing the camera.
     */
    private val cameraOpenCloseLock = Semaphore(1)


    /**
     * An additional thread for running tasks that shouldn't block the UI.
     */
    private var backgroundThread: HandlerThread? = null

    /**
     * A [Handler] for running tasks in the background.
     */
    private var backgroundHandler: Handler? = null

    /**
     * An [ImageReader] that handles still image capture.
     */
    private var imageReader: ImageReader? = null

    private var mCameraFacing = CameraCharacteristics.LENS_FACING_FRONT


    private var dirPath = Environment.getExternalStorageDirectory()

    private var mAutoFocusSupported = false

    private var state =
        STATE_PREVIEW


    var mExpectSize: Size? = null

    var mPreviewing = false

    private lateinit var mCoordTransform: Matrix

    private val stateCallback = object : CameraDevice.StateCallback() {

        override fun onOpened(cameraDevice: CameraDevice) {
            cameraOpenCloseLock.release()
            mCameraDevice = cameraDevice
            createCameraPreviewSession()
        }

        override fun onDisconnected(cameraDevice: CameraDevice) {
            cameraOpenCloseLock.release()
            cameraDevice.close()
            mCameraDevice = null
        }

        override fun onError(cameraDevice: CameraDevice, error: Int) {
            onDisconnected(cameraDevice)
        }

    }




    private val captureCallback = object : CameraCaptureSession.CaptureCallback() {

        private fun process(result: CaptureResult) {
            when (state) {
                STATE_PREVIEW -> Unit // Do nothing when the camera preview is working normally.
                STATE_WAITING_LOCK -> capturePicture(result)
                STATE_WAITING_PRECAPTURE -> {
                    // CONTROL_AE_STATE can be null on some devices
                    val aeState = result.get(CaptureResult.CONTROL_AE_STATE)
                    if (aeState == null ||
                        aeState == CaptureResult.CONTROL_AE_STATE_PRECAPTURE ||
                        aeState == CaptureRequest.CONTROL_AE_STATE_FLASH_REQUIRED) {
                        state =
                            STATE_WAITING_NON_PRECAPTURE
                    }
                }
                STATE_WAITING_NON_PRECAPTURE -> {
                    // CONTROL_AE_STATE can be null on some devices
                    val aeState = result.get(CaptureResult.CONTROL_AE_STATE)
                    if (aeState == null || aeState != CaptureResult.CONTROL_AE_STATE_PRECAPTURE) {
                        state =
                            STATE_PICTURE_TAKEN
                        captureStillPicture()
                    }
                }
            }
        }

        private fun capturePicture(result: CaptureResult) {
            val afState = result.get(CaptureResult.CONTROL_AF_STATE)
            if (afState == null) {
                captureStillPicture()
            } else if (afState == CaptureResult.CONTROL_AF_STATE_FOCUSED_LOCKED
                || afState == CaptureResult.CONTROL_AF_STATE_NOT_FOCUSED_LOCKED) {
                // CONTROL_AE_STATE can be null on some devices
                val aeState = result.get(CaptureResult.CONTROL_AE_STATE)
                if (aeState == null || aeState == CaptureResult.CONTROL_AE_STATE_CONVERGED) {
                    state =
                        STATE_PICTURE_TAKEN
                    captureStillPicture()
                } else {
                    runPrecaptureSequence()
                }
            }
        }

        override fun onCaptureProgressed(session: CameraCaptureSession,
                                         request: CaptureRequest,
                                         partialResult: CaptureResult
        ) {
            process(partialResult)
        }

        override fun onCaptureCompleted(session: CameraCaptureSession,
                                        request: CaptureRequest,
                                        result: TotalCaptureResult
        ) {
            process(result)
        }

    }

    private val onImageAvailableListener = ImageReader.OnImageAvailableListener {
        backgroundHandler?.post{
            val buffer = it.acquireNextImage().planes[0].buffer
            val bytearray = ByteArray(buffer.remaining())
            buffer.get(bytearray)
            var output: FileOutputStream? = null
            try {
                output = FileOutputStream(File(dirPath,"now.jpg"))
                if(mCameraFacing == CameraCharacteristics.LENS_FACING_BACK) {
                    output.write(bytearray)
                }else{

                    val resource = BitmapFactory.decodeByteArray(bytearray,0,bytearray.size)
                    val matrix = Matrix()
                    matrix.setScale(-1f,1f)
                    Bitmap.createBitmap(resource,0,0,resource.width,
                        resource.height,matrix,false).apply {
                        this.compress(Bitmap.CompressFormat.JPEG,100,output)
                        resource.recycle()
                        this.recycle()
                    }
                }
                output.flush()
                output.close()
            }catch (e:Exception){
                e.printStackTrace()
            }
        }
    }

    private val TAG = "Camera"

    private var sensorOrientation= 0

    private val outputSurfaces = arrayListOf<Surface>()

    private val textures = arrayListOf<TextureView>()

    private val surfaceTextures = arrayListOf<SurfaceTexture>()

    private fun startBackgroundThread() {
        backgroundThread = HandlerThread("CameraBackground").also { it.start() }
        backgroundHandler = Handler(backgroundThread?.looper)
    }

    /**
     * Stops the background thread and its [Handler].
     */
    private fun stopBackgroundThread() {
        backgroundThread?.quitSafely()
        try {
            backgroundThread?.join()
            backgroundThread = null
            backgroundHandler = null
        } catch (e: InterruptedException) {
            Log.e(TAG, e.toString())
        }
    }
    fun setAspectRatio(ratio:Int){
//        closeCamera()
//        cameraSurfaceview?.setAspectRatio(ratio)
//        cameraSurfaceview?.post {
//            openCamera(cameraSurfaceview!!.width,cameraSurfaceview!!.height)
//        }

    }


    @SuppressLint("MissingPermission")
    private fun openCamera(width: Int, height: Int) {

        setUpCameraOutputs(width, height)
        textures.forEach {
            configureTransform(it,it.width,it.height)
            outputSurfaces.add(Surface(it.surfaceTexture))
        }
        textures.clear()
        surfaceTextures.forEach {
            it.setDefaultBufferSize(previewSize.width,previewSize.height)
            outputSurfaces.add(Surface(it))
        }
        surfaceTextures.clear()
//        configureTransform(width, height)
        val manager = context.getSystemService(Context.CAMERA_SERVICE) as CameraManager
        try {
            // Wait for camera to open - 2.5 seconds is sufficient
            if (!cameraOpenCloseLock.tryAcquire(2500, TimeUnit.MILLISECONDS)) {
                throw RuntimeException("Time out waiting to lock camera opening.")
            }
            manager.openCamera(cameraId, stateCallback, backgroundHandler)
        } catch (e: CameraAccessException) {
            Log.e(ContentValues.TAG, e.toString())
        } catch (e: InterruptedException) {
            throw RuntimeException("Interrupted while trying to lock camera opening.", e)
        }

    }


    private fun closeCamera() {
        try {
            cameraOpenCloseLock.acquire()
            captureSession?.close()
            captureSession = null
            mCameraDevice?.close()
            mCameraDevice = null
            imageReader?.close()
            imageReader = null
        } catch (e: InterruptedException) {
            throw RuntimeException("Interrupted while trying to lock camera closing.", e)
        } finally {
            cameraOpenCloseLock.release()
        }
    }

    fun  takePicture(){
        if(mAutoFocusSupported){
            lockFocus()
        }else{
            captureStillPicture()
        }

    }


    fun turnCamera(){
        closeCamera()
        if(mCameraFacing == CameraCharacteristics.LENS_FACING_BACK){
            mCameraFacing = CameraCharacteristics.LENS_FACING_FRONT
        }else{
            mCameraFacing = CameraCharacteristics.LENS_FACING_BACK
        }

        openCamera(mExpectSize!!.width,mExpectSize!!.height)
    }


    private fun captureStillPicture() {
        try {
            if (context == null || mCameraDevice == null) return
            val rotation = (context as Activity).windowManager.defaultDisplay.rotation

            // This is the CaptureRequest.Builder that we use to take a picture.
            val captureBuilder = mCameraDevice?.createCaptureRequest(
                CameraDevice.TEMPLATE_STILL_CAPTURE)?.apply {
                addTarget(imageReader!!.surface)

                // Sensor orientation is 90 for most devices, or 270 for some devices (eg. Nexus 5X)
                // We have to take that into account and rotate JPEG properly.
                // For devices with orientation of 90, we return our mapping from ORIENTATIONS.
                // For devices with orientation of 270, we need to rotate the JPEG 180 degrees.
                set(
                    CaptureRequest.JPEG_ORIENTATION,
                    (ORIENTATIONS.get(rotation) + sensorOrientation + 270) % 360)

                // Use the same AE and AF modes as the preview.
                set(
                    CaptureRequest.CONTROL_AF_MODE,
                    CaptureRequest.CONTROL_AF_MODE_CONTINUOUS_PICTURE)
            }?.also {
                // setAutoFlash(it)
            }

            val captureCallback = object : CameraCaptureSession.CaptureCallback() {

                override fun onCaptureCompleted(session: CameraCaptureSession,
                                                request: CaptureRequest,
                                                result: TotalCaptureResult
                ) {
                    unlockFocus()
                }
            }

            captureSession?.apply {
                stopRepeating()
                abortCaptures()
                capture(captureBuilder?.build()!!, captureCallback, null)
            }
        } catch (e: CameraAccessException) {
            Log.e(TAG, e.toString())
        }

    }

    private fun runPrecaptureSequence() {
        try {
            // This is how to tell the camera to trigger.
            previewRequestBuilder.set(
                CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER,
                CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER_START)
            // Tell #captureCallback to wait for the precapture sequence to be set.
            state =
                STATE_WAITING_PRECAPTURE
            captureSession?.capture(previewRequestBuilder.build(), captureCallback,
                backgroundHandler)
        } catch (e: CameraAccessException) {
            Log.e(TAG, e.toString())
        }

    }

    private fun lockFocus() {
        try {
            // This is how to tell the camera to lock focus.
            previewRequestBuilder.set(
                CaptureRequest.CONTROL_AF_TRIGGER,
                CameraMetadata.CONTROL_AF_TRIGGER_START)
            // Tell #captureCallback to wait for the lock.
            state =
                STATE_WAITING_LOCK
            captureSession?.capture(previewRequestBuilder.build(), captureCallback,
                backgroundHandler)
        } catch (e: CameraAccessException) {
            Log.e(TAG, e.toString())
        }

    }

    private fun unlockFocus() {
        try {
            // Reset the auto-focus trigger
            previewRequestBuilder.set(
                CaptureRequest.CONTROL_AF_TRIGGER,
                CameraMetadata.CONTROL_AF_TRIGGER_CANCEL)
            // setAutoFlash(previewRequestBuilder)
            captureSession?.capture(previewRequestBuilder.build(), captureCallback,
                backgroundHandler)
            // After this, the camera will go back to the normal state of preview.
            state = STATE_PREVIEW
            captureSession?.setRepeatingRequest(previewRequest, captureCallback,
                backgroundHandler)
        } catch (e: CameraAccessException) {
            Log.e(TAG, e.toString())
        }

    }


    private fun createCameraPreviewSession() {
        try {
//            val texture = mSurfaceTexture!!
//            // We configure the size of default buffer to be the size of camera preview we want.
//            texture.setDefaultBufferSize(previewSize.width, previewSize.height)
//
//            // This is the output Surface we need to start preview.
//            val surface = Surface(texture)

            // We set up a CaptureRequest.Builder with the output Surface.
            previewRequestBuilder = mCameraDevice!!.createCaptureRequest(
                CameraDevice.TEMPLATE_RECORD
            )
            outputSurfaces.forEach {
                previewRequestBuilder.addTarget(it)
            }


            // Here, we create a CameraCaptureSession for camera preview.
            mCameraDevice?.createCaptureSession(
               outputSurfaces,
                object : CameraCaptureSession.StateCallback() {

                    override fun onConfigured(cameraCaptureSession: CameraCaptureSession) {
                        // The camera is already closed
                        if (mCameraDevice == null) return

                        // When the session is SurfaceViewAvailable, we start displaying the preview.
                        captureSession = cameraCaptureSession
                        try {
//                            previewRequestBuilder.set(CaptureRequest.CONTROL_MODE,CaptureRequest.CONTROL_MODE_AUTO)
                            // Auto focus should be continuous for camera preview.
                            previewRequestBuilder.set(
                                CaptureRequest.CONTROL_AF_MODE,
                                CaptureRequest.CONTROL_AF_MODE_CONTINUOUS_PICTURE)
//                            previewRequestBuilder.set(CaptureRequest.CONTROL_AE_LOCK,false)
//                            previewRequestBuilder.set(CaptureRequest.CONTROL_AE_MODE,
//                                CaptureRequest.CONTROL_AE_MODE_ON)
                            previewRequestBuilder.set(
                                CaptureRequest.CONTROL_AE_TARGET_FPS_RANGE,
                                getRange())
                            // Flash is automatically enabled when necessary.

                            // Finally, we start displaying the camera preview.
                            previewRequest = previewRequestBuilder.build()
                            captureSession?.setRepeatingRequest(previewRequest,
                                captureCallback, backgroundHandler)
                        } catch (e: CameraAccessException) {
                            Log.e(TAG, e.toString())
                        }

                    }

                    override fun onConfigureFailed(session: CameraCaptureSession) {

                    }
                }, null)
        } catch (e: CameraAccessException) {
            Log.e(ContentValues.TAG, e.toString())
        }

    }

    private fun getRange(): Range<Int> {
        val manager = (context as Activity).getSystemService(Context.CAMERA_SERVICE) as CameraManager
        val characteristics = manager.getCameraCharacteristics(cameraId)
        val ranges = characteristics.get(CameraCharacteristics.CONTROL_AE_AVAILABLE_TARGET_FPS_RANGES)
        var result = Range.create(0,10)
        ranges!!.forEach {
            //            val upper = it.upper
            val lower = it.lower
            if(lower>0){
                if(result == null || result.lower < lower){
                    result = it
                }
            }
        }
        return result
    }

    fun FocusByTap(x:Float,y: Float){
        val range = getFocusRange(x, y)
        previewRequestBuilder.set(CaptureRequest.CONTROL_AF_MODE, CaptureRequest.CONTROL_AF_MODE_AUTO)
        previewRequestBuilder.set(CaptureRequest.CONTROL_MODE, CaptureRequest.CONTROL_MODE_AUTO)
        previewRequestBuilder.set(CaptureRequest.CONTROL_AF_REGIONS, arrayOf(range))
        previewRequestBuilder.set(CaptureRequest.CONTROL_AE_REGIONS, arrayOf(range))
        previewRequestBuilder.set(CaptureRequest.CONTROL_AF_TRIGGER, CaptureRequest.CONTROL_AF_TRIGGER_IDLE)
        captureSession!!.setRepeatingRequest(previewRequestBuilder.build(),null,backgroundHandler)

        previewRequestBuilder.set(CaptureRequest.CONTROL_AF_TRIGGER, CaptureRequest.CONTROL_AF_TRIGGER_START)
        captureSession!!.capture(previewRequestBuilder.build(),null,backgroundHandler)
    }

    private fun getFocusRange(centerx:Float,centery:Float): MeteringRectangle {

//        val area = Utils.dp2px(context,30f).toInt()
//        val left = Utils.clamp((centerx-area).toInt(),0,previewSize.height-area)
//        val top = Utils.clamp((centery-area).toInt(),0,previewSize.width-area)
//        val rectf = RectF(left.toFloat(), top.toFloat(), (left+area).toFloat(), (top+area).toFloat())
        val rectf = RectF(0F,0F,1F,1F)
        var cameraRect = RectF()
        mCoordTransform.mapRect(cameraRect,rectf)
        val result = Rect(Math.round(cameraRect.left),Math.round(cameraRect.top),
            Math.round(cameraRect.right),Math.round(cameraRect.bottom))
        return MeteringRectangle(result,1000)

    }

    fun addOutputSurface(surface: Surface){
        outputSurfaces.add(surface)
    }

    fun addTexture(texture: TextureView){
        textures.add(texture)
    }

    fun addSurfaceTexture(surfaceTexture: SurfaceTexture){
        surfaceTextures.add(surfaceTexture)
    }

    /**
     * Sets up member variables related to camera.
     *
     * @param width  The width of available size for camera preview
     * @param height The height of available size for camera preview
     */
    private fun setUpCameraOutputs(width: Int, height: Int) {

        val manager = (context as Activity).getSystemService(Context.CAMERA_SERVICE) as CameraManager
        try {
            for (cameraId in manager.cameraIdList) {
                val characteristics = manager.getCameraCharacteristics(cameraId)

                // We don't use a front facing camera in this sample.
                if(characteristics.get(CameraCharacteristics.LENS_FACING) != mCameraFacing){
                    continue
                }
                mCameraFacing = characteristics.get(CameraCharacteristics.LENS_FACING)!!
                val afAvailableModes = characteristics.get(CameraCharacteristics.CONTROL_AF_AVAILABLE_MODES)
                if(afAvailableModes!!.size ==0 ||
                    (afAvailableModes!!.size == 1 &&
                            afAvailableModes!![0] == CameraCharacteristics.CONTROL_AF_MODE_OFF)){
                    mAutoFocusSupported = false
                }else{
                    mAutoFocusSupported = true
                }

                val map = characteristics.get(
                    CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP) ?: continue

                // For still image captures, we use the largest available size.
                val largest = Collections.max(
                    Arrays.asList(*map.getOutputSizes(ImageFormat.JPEG)),
                    CompareSizesByArea())

                imageReader = ImageReader.newInstance(largest.width, largest.height,
                    ImageFormat.JPEG, /*maxImages*/ 2).apply {
                    setOnImageAvailableListener(onImageAvailableListener, backgroundHandler)
                }

                // Find out if we need to swap dimension to get the preview size relative to sensor
                // coordinate.
                val displayRotation = context.windowManager.defaultDisplay.rotation

                sensorOrientation = characteristics.get(CameraCharacteristics.SENSOR_ORIENTATION)!!
                val swappedDimensions = areDimensionsSwapped(displayRotation)

                val displaySize = Point()
                context.windowManager.defaultDisplay.getSize(displaySize)
                val rotatedPreviewWidth = if (swappedDimensions) height else width
                val rotatedPreviewHeight = if (swappedDimensions) width else height
                var maxPreviewWidth = if (swappedDimensions) displaySize.y else displaySize.x
                var maxPreviewHeight = if (swappedDimensions) displaySize.x else displaySize.y

                if (maxPreviewWidth > MAX_PREVIEW_WIDTH) maxPreviewWidth =
                    MAX_PREVIEW_WIDTH
                if (maxPreviewHeight > MAX_PREVIEW_HEIGHT) maxPreviewHeight =
                    MAX_PREVIEW_HEIGHT

                // Danger, W.R.! Attempting to use too large a preview size could  exceed the camera
                // bus' bandwidth limitation, resulting in gorgeous previews but the storage of
                // garbage capture data.
                previewSize = chooseOptimalSize(map.getOutputSizes(SurfaceTexture::class.java),
                    rotatedPreviewWidth, rotatedPreviewHeight,
                    maxPreviewWidth, maxPreviewHeight,
                    Size(rotatedPreviewWidth,rotatedPreviewHeight)
                )
                Log.e(TAG,"preview width ${previewSize.width},${previewSize.height}")

//                 We fit the aspect ratio of TextureView to the size of preview we picked.
//                if (context.resources.configuration.orientation == Configuration.ORIENTATION_LANDSCAPE) {
//                    context.runOnUiThread {
//                        cameraSurfaceview.setAspectRatio(previewSize.width, previewSize.height)
//                    }
//                } else {
//                    context.runOnUiThread {
//                        cameraSurfaceview.setAspectRatio(previewSize.height, previewSize.width)
//                    }
//                }

                // Check if the flash is supported.


                this.cameraId = cameraId
                initTransform(characteristics,width,height)
                // We've found a viable camera and finished setting up member variables,
                // so we don't need to iterate through other available cameras.
                return
            }
        } catch (e: CameraAccessException) {
            Log.e(TAG, e.toString())
        } catch (e: NullPointerException) {
            // Currently an NPE is thrown when the Camera2API is used but not supported on the
            // device this code runs.
        }

    }

    private fun initTransform(characteristics: CameraCharacteristics, width: Int, height: Int) {
        val previewRect = RectF(0f,0f,width.toFloat(),height.toFloat())
        val rect = characteristics.get(CameraCharacteristics.SENSOR_INFO_ACTIVE_ARRAY_SIZE)
        val sensorOrientation = characteristics.get(CameraCharacteristics.SENSOR_ORIENTATION)
        val transform = Matrix()
        transform?.let {
            it.setScale(if(mCameraFacing == CameraCharacteristics.LENS_FACING_FRONT) -1f else 1f,1f)
            it.postRotate(-sensorOrientation!!.toFloat())
            it.mapRect(previewRect)
            val fill = Matrix()
            fill.setRectToRect(previewRect, RectF(rect), Matrix.ScaleToFit.FILL)
            it.setConcat(fill,it)
        }
        mCoordTransform = transform

    }

    private fun configureTransform(texture: TextureView,viewWidth: Int, viewHeight: Int) {
        context ?: return
        val rotation = (context as Activity).windowManager.defaultDisplay.rotation
        val matrix = Matrix()
        val viewRect = RectF(0f, 0f, viewWidth.toFloat(), viewHeight.toFloat())
        val bufferRect = RectF(0f, 0f, previewSize.height.toFloat(), previewSize.width.toFloat())
        val centerX = viewRect.centerX()
        val centerY = viewRect.centerY()

        if (Surface.ROTATION_90 == rotation || Surface.ROTATION_270 == rotation) {
            bufferRect.offset(centerX - bufferRect.centerX(), centerY - bufferRect.centerY())
            val scale = Math.max(
                viewHeight.toFloat() / previewSize.height,
                viewWidth.toFloat() / previewSize.width)
            with(matrix) {
                setRectToRect(viewRect, bufferRect, Matrix.ScaleToFit.FILL)
                postScale(scale, scale, centerX, centerY)
                postRotate((90 * (rotation - 2)).toFloat(), centerX, centerY)
            }
        } else if (Surface.ROTATION_180 == rotation) {
            matrix.postRotate(180f, centerX, centerY)
        }
        texture.setTransform(matrix)
    }

    private fun chooseOptimalSize(
        choices: Array<Size>,
        textureViewWidth: Int,
        textureViewHeight: Int,
        maxWidth: Int,
        maxHeight: Int,
        aspectRatio: Size
    ): Size {

        // Collect the supported resolutions that are at least as big as the preview Surface
        val bigEnough = ArrayList<Size>()
        // Collect the supported resolutions that are smaller than the preview Surface
        val notBigEnough = ArrayList<Size>()
        val w = aspectRatio.width
        val h = aspectRatio.height
        for (option in choices) {
            if (option.width <= maxWidth && option.height <= maxHeight &&
                (option.height == option.width * h / w || option.height == textureViewHeight)) {
                if (option.width >= textureViewWidth && option.height >= textureViewHeight) {
                    bigEnough.add(option)
                } else {
                    notBigEnough.add(option)
                }
            }
        }

        // Pick the smallest of those big enough. If there is no one big enough, pick the
        // largest of those not big enough.
        if (bigEnough.size > 0) {
            return Collections.min(bigEnough, CompareSizesByArea())
        } else if (notBigEnough.size > 0) {
            return Collections.max(notBigEnough, CompareSizesByArea())
        } else {
            Log.e(TAG, "Couldn't find any suitable preview size")
            return choices[0]
        }
    }

    /**
     * Determines if the dimensions are swapped given the phone's current rotation.
     *
     * @param displayRotation The current rotation of the display
     *
     * @return true if the dimensions are swapped, false otherwise.
     */
    private fun areDimensionsSwapped(displayRotation: Int): Boolean {
        var swappedDimensions = false
        when (displayRotation) {
            Surface.ROTATION_0, Surface.ROTATION_180 -> {
                if (sensorOrientation == 90 || sensorOrientation == 270) {
                    swappedDimensions = true
                }

            }
            Surface.ROTATION_90, Surface.ROTATION_270 -> {
                if (sensorOrientation == 0 || sensorOrientation == 180) {
                    swappedDimensions = true
                }
            }
            else -> {
                Log.e(ContentValues.TAG, "Display rotation is invalid: $displayRotation")
            }
        }
        return swappedDimensions
    }

    fun StartPreview() {
        startBackgroundThread()
//        if(mSurfaceTexture == null){
//            throw RuntimeException("SurfaceTexture is not init")
//        }
        openCamera(mExpectSize!!.width,mExpectSize!!.height)
        mPreviewing = true
    }

    fun StopPreview(){
        closeCamera()
        stopBackgroundThread()
        mPreviewing = false
    }




    inner class CompareSizesByArea : Comparator<Size> {
        override fun compare(size1: Size, size2: Size): Int {
            return java.lang.Long.signum(size1.width.toLong() * size1.height - size2.width.toLong() * size2.height)
        }
    }

}